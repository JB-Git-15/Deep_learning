{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Own implementation of cat vs non cats challenge  (12/2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "import scipy\n",
    "from PIL import Image\n",
    "from scipy import ndimage\n",
    "#from lr_utils import load_dataset\n",
    "\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset():\n",
    "    train_dataset = h5py.File('datasets/train_catvnoncat.h5', \"r\")\n",
    "    train_set_x_orig = np.array(train_dataset[\"train_set_x\"][:]) # your train set features\n",
    "    train_set_y_orig = np.array(train_dataset[\"train_set_y\"][:]) # your train set labels\n",
    "\n",
    "    test_dataset = h5py.File('datasets/test_catvnoncat.h5', \"r\")\n",
    "    test_set_x_orig = np.array(test_dataset[\"test_set_x\"][:]) # your test set features\n",
    "    test_set_y_orig = np.array(test_dataset[\"test_set_y\"][:]) # your test set labels\n",
    "\n",
    "    classes = np.array(test_dataset[\"list_classes\"][:]) # the list of classes\n",
    "    \n",
    "    train_set_y_orig = train_set_y_orig.reshape((1, train_set_y_orig.shape[0]))\n",
    "    test_set_y_orig = test_set_y_orig.reshape((1, test_set_y_orig.shape[0]))\n",
    "    \n",
    "    return train_set_x_orig, train_set_y_orig, test_set_x_orig, test_set_y_orig, classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set_x_orig, train_set_y_orig, test_set_x_orig, test_set_y_orig, classes = load_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.66"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# majority class prediction\n",
    "\n",
    "# if predict all ones : 34 % of ones in the training set\n",
    "np.sum(train_set_y_orig)/train_set_y_orig.size\n",
    "\n",
    "# if predict all ones : 66 % of ones in the test set\n",
    "np.sum(test_set_y_orig)/test_set_y_orig.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "m =  train_set_x_orig.shape[0] # pictures training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape and normalize the data\n",
    "X_train = np.reshape(train_set_x_orig, (train_set_x_orig.shape[1]*train_set_x_orig.shape[2]*train_set_x_orig.shape[3],-1))\n",
    "Y_train = train_set_y_orig\n",
    "X_train = X_train/255\n",
    "m1      = X_train.shape[1]\n",
    "\n",
    "X_test  = np.reshape(test_set_x_orig,(test_set_x_orig.shape[1]*test_set_x_orig.shape[2]*test_set_x_orig.shape[3],-1))\n",
    "X_test  = X_test/255\n",
    "m2      = X_test.shape[1]\n",
    "\n",
    "Y_test  = test_set_y_orig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic regression gives an accuracy of 34.0 %\n"
     ]
    }
   ],
   "source": [
    "####### Essayer rÃ©gression logistique\n",
    "\n",
    "clf = LogisticRegressionCV(random_state=3, max_iter = 3000).fit(X_train.T, np.ravel(Y_train))\n",
    "Prediction = clf.predict(X_test.T)\n",
    "\n",
    "print(\"Logistic regression gives an accuracy of \" + str(100- np.mean(np.abs(Prediction - Y_test))*100) + \" %\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ReLu(x):\n",
    "    return np.maximum(0,x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ReLu_prime(z):\n",
    "    return (z>0)*1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Sigmoid(z):\n",
    "    return 1/(1+np.exp(-z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Sigmoid_prime(z):\n",
    "    return Sigmoid(z)*(1-Sigmoid(z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Init_parameters(X,y,L,Num_units_in_hidden_layers):\n",
    "    \n",
    "    m                          = X.shape[1]   # examples \n",
    "    Num_units_in_hidden_layers = np.reshape(Num_units_in_hidden_layers,(Num_units_in_hidden_layers.size,-1))\n",
    "    \n",
    "    if (Num_units_in_hidden_layers.size != (L-1)):\n",
    "        print('The number of units in the hidden layer are not consistent with the number of layers')\n",
    "    else:\n",
    "        print('Initializing the parameters for a network with ' + str(L-1) + ' hidden layers')\n",
    "        print('Number of units in hidden layers : ' + str(Num_units_in_hidden_layers.T))\n",
    "\n",
    "    \n",
    "    Num_u            = np.ones((L+1,1))    \n",
    "    Num_u[0]         = X.shape[0]\n",
    "    Num_u[-1]        = 1\n",
    "    Num_u[1:-1]      = Num_units_in_hidden_layers\n",
    "                \n",
    "    W_weights        = {}\n",
    "    B_biases         = {}\n",
    "\n",
    "    for u in range(L):\n",
    "        W_weights[\"W_\" + str(int(u+1))] =  np.random.randn(int(Num_u[u+1]),int(Num_u[u])) / np.sqrt(Num_u[u])\n",
    "        B_biases[\"B_\" + str(int(u+1))]  =  np.zeros((int(Num_u[u+1]),1)) \n",
    "        \n",
    "    A_activations    = {}  # activation functions    \n",
    "    for u in range(L+1):    \n",
    "        if u == 0:\n",
    "            A_activations[\"A_0\"] = X\n",
    "        else:    \n",
    "            A_activations[\"A_\" + str(int(u))]  = np.zeros((int(Num_u[int(u)]),m))\n",
    "    \n",
    "    Z_scores         = {} #scores                \n",
    "    for u in range(1,L+1):\n",
    "            Z_scores[\"Z_\" + str(int(u))]       = np.zeros((int(Num_u[int(u)]),m))\n",
    "          \n",
    "    G_non_lin            = {}\n",
    "    G_non_lin_derivative = {}\n",
    "    for u in range(L):    \n",
    "        if u != (L-1):\n",
    "            G_non_lin[\"g_\" + str(int(u+1))] = ReLu\n",
    "            G_non_lin_derivative[\"g'_\" + str(int(u+1))] = ReLu_prime\n",
    "        else:\n",
    "            G_non_lin[\"g_\" + str(int(u+1))] = Sigmoid\n",
    "            G_non_lin_derivative[\"g'_\" + str(int(u+1))] = Sigmoid_prime\n",
    "\n",
    "   \n",
    "    return W_weights,B_biases, Z_scores, A_activations, G_non_lin, G_non_lin_derivative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing the parameters for a network with 2 hidden layers\n",
      "Number of units in hidden layers : [[5 6]]\n"
     ]
    }
   ],
   "source": [
    "L = 3\n",
    "W_weights,B_biases,Z_scores,A_activations,G_non_lin,G_non_lin_derivative = Init_parameters(X_train,Y_train,L,np.array([[5],[6]]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Compute_cost(A_s,Y,L):\n",
    "    m      = Y.size\n",
    "    A_end  = A_s[\"A_\"+str(L)]\n",
    "    J      = np.sum(-(1-Y)*np.log(1-A_end)-Y*np.log(A_end))/m # compute \n",
    "    return J"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#A_activations[\"A_3\"] = Sigmoid(.9*Y_train +  np.random.rand(1,209)*.001)\n",
    "#Compute_cost(A_activations,Y_train,L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12288, 209)\n",
      "(5, 12288)\n"
     ]
    }
   ],
   "source": [
    "print(A_activations[\"A_0\"].shape)\n",
    "print(W_weights[\"W_1\"].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Forward_pass(L, W_weights,B_biases, Z_scores, A_activations,G_non_lin):\n",
    "\n",
    "    for u in range(L):\n",
    "        Z_scores[\"Z_\" + str(int(u+1))]      = np.dot(W_weights[\"W_\" + str(int(u+1))],A_activations[\"A_\" + str(int(u))]) + B_biases[\"B_\" + str(int(u+1))]\n",
    "        A_activations[\"A_\" + str(int(1+u))] = G_non_lin[\"g_\"+ str(int(u+1))](Z_scores[\"Z_\" + str(int(u+1))])\n",
    "    \n",
    "    return A_activations,Z_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Back_propagation(A_activations,W_weights,Z_scores,Y,L,G_non_lin_derivative):\n",
    "    \n",
    "    m                    = Y.size\n",
    "    A_end                = A_activations[\"A_\"+str(L)]\n",
    "    Delta_activations_dA = {}\n",
    "    Delta_scores_dZ      = {}\n",
    "    dW_s                 = {}\n",
    "    dB_s                 = {}\n",
    "    Delta_activations_dA[\"dA_\"+ str(int(L))]   = -np.divide(Y,A_end)  +  np.divide(1-Y,1-A_end)\n",
    "  \n",
    "       \n",
    "    for u in range(L,0,-1):    \n",
    "        Delta_scores_dZ[\"dZ_\"+ str(int(u))]            =  Delta_activations_dA[\"dA_\" + str(int(u))]*G_non_lin_derivative[\"g'_\" + str(int(u))](Z_scores[\"Z_\" + str(int(u))]) \n",
    "        dW_s[\"dW_\"+ str(int(u))]                       =  np.dot(Delta_scores_dZ[\"dZ_\"+ str(int(u))],A_activations[\"A_\"+str(u-1)].T)/m\n",
    "        dB_s[\"dB_\"+ str(int(u))]                       =  np.sum(Delta_scores_dZ[\"dZ_\"+ str(int(u))],axis = 1,keepdims = True)/m\n",
    "        Delta_activations_dA[\"dA_\" + str(int(u-1))]    =  np.dot(W_weights[\"W_\" + str(int(u))].T,Delta_scores_dZ[\"dZ_\"+ str(int(u))]) \n",
    " \n",
    "                         \n",
    "    return dW_s,dB_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Update_parameters(Weigth_matrices,dW_s,B_biases,dB_s,Learning_rate):\n",
    "    for u in range(1,len(Weigth_matrices)):      \n",
    "        Weigth_matrices[\"W_\"+str(u)] =  Weigth_matrices[\"W_\"+str(u)]  - Learning_rate*dW_s[\"dW_\"+ str(u)]\n",
    "        B_biases[\"B_\"+str(u)]        =  B_biases[\"B_\"+str(u)]  - Learning_rate*dB_s[\"dB_\"+ str(u)]\n",
    "  \n",
    "    return Weigth_matrices,B_biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Modele_Deep_network(X_train, Y_train, X_test, Y_test, Learning_rate, Num_iterations, L, Num_units_in_hidden_layers):\n",
    "    \n",
    "    W_weights,B_biases, Z_scores, A_activations, G_non_lin,G_non_lin_derivative = Init_parameters(X_train,Y_train,L,Num_units_in_hidden_layers)\n",
    "             \n",
    "    Cost_list      = [] \n",
    "    Iteration_list = [] \n",
    "    for num_iter in range(Num_iterations+1):\n",
    "            A_activations,Z_scores = Forward_pass(L, W_weights,B_biases, Z_scores, A_activations,G_non_lin)\n",
    "            dW_s,dB_s              = Back_propagation(A_activations,W_weights,Z_scores,Y_train,L,G_non_lin_derivative) \n",
    "            W_weights, B_biases    = Update_parameters(W_weights,dW_s,B_biases,dB_s,Learning_rate)\n",
    "        \n",
    "            if (num_iter%50 == 0):\n",
    "                Cost = Compute_cost(A_activations,Y_train,L)\n",
    "                print(\"Cost after the \"+ str(num_iter) +\"(st) iteration : \" + str(Cost)) \n",
    "                Cost_list.append(Cost) \n",
    "                Iteration_list.append(num_iter)\n",
    "    \n",
    "    #Accuracy on the train set\n",
    "    Preds_train = np.round(A_activations[\"A_\"+str(L)])\n",
    "    print(\"Accuracy on the train set : \" + str(100- np.mean(np.absolute(Preds_train - Y_train))*100))\n",
    "\n",
    "    #Accuracy on the test set\n",
    "    W_weights2,B_biases2, Z_scores2, A_activations2, G_non_lin,G_non_lin_derivative  = Init_parameters(X_test,Y_test,L,Num_units_in_hidden_layers)\n",
    "    A_activations2,x = Forward_pass(L, W_weights2,B_biases2, Z_scores2, A_activations2,G_non_lin)\n",
    "    Preds_test       = np.round(A_activations2[\"A_\"+str(L)])\n",
    "    print(\"Accuracy on the test set : \" + str(np.mean((Preds_test == Y_test))*100))\n",
    "       \n",
    "    d = {}\n",
    "    d['W'] = W_weights\n",
    "    d['B'] = B_biases\n",
    "    d['Acc train set'] = Preds_train\n",
    "    d['Acc test set']  = Preds_test\n",
    "    d['Cost'] = Cost_list\n",
    "    d['Iteration'] = Iteration_list\n",
    "        \n",
    "    print(Preds_train)    \n",
    "    print(Preds_test)    \n",
    "    \n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing the parameters for a network with 2 hidden layers\n",
      "Number of units in hidden layers : [[20 10]]\n",
      "Cost after the 0(st) iteration : 0.790715664168443\n",
      "Cost after the 50(st) iteration : 0.6584788009731215\n",
      "Cost after the 100(st) iteration : 0.6436679924719897\n",
      "Cost after the 150(st) iteration : 0.6377977812880209\n",
      "Cost after the 200(st) iteration : 0.6328198748698797\n",
      "Cost after the 250(st) iteration : 0.6280232607167069\n",
      "Cost after the 300(st) iteration : 0.6234886322308884\n",
      "Cost after the 350(st) iteration : 0.6195599548456595\n",
      "Cost after the 400(st) iteration : 0.6160851125878277\n",
      "Cost after the 450(st) iteration : 0.612861196614648\n",
      "Cost after the 500(st) iteration : 0.609790553983561\n",
      "Cost after the 550(st) iteration : 0.6068915615360523\n",
      "Cost after the 600(st) iteration : 0.6037857757045847\n",
      "Cost after the 650(st) iteration : 0.6009225125731451\n",
      "Cost after the 700(st) iteration : 0.5982135339080641\n",
      "Cost after the 750(st) iteration : 0.595687654663926\n",
      "Cost after the 800(st) iteration : 0.5932836037170188\n",
      "Cost after the 850(st) iteration : 0.5909339417220406\n",
      "Cost after the 900(st) iteration : 0.5886443293701066\n",
      "Cost after the 950(st) iteration : 0.5863981124114861\n",
      "Cost after the 1000(st) iteration : 0.5841777807824652\n",
      "Cost after the 1050(st) iteration : 0.582007920326555\n",
      "Cost after the 1100(st) iteration : 0.5798502895583116\n",
      "Cost after the 1150(st) iteration : 0.5777191286882798\n",
      "Cost after the 1200(st) iteration : 0.5756082366836001\n",
      "Cost after the 1250(st) iteration : 0.5735107841143957\n",
      "Cost after the 1300(st) iteration : 0.5714213522179985\n",
      "Cost after the 1350(st) iteration : 0.5693451353152753\n",
      "Cost after the 1400(st) iteration : 0.5672611771611308\n",
      "Cost after the 1450(st) iteration : 0.5651846381753933\n",
      "Cost after the 1500(st) iteration : 0.5631074123639536\n",
      "Cost after the 1550(st) iteration : 0.5610324598028082\n",
      "Cost after the 1600(st) iteration : 0.5589619078031085\n",
      "Cost after the 1650(st) iteration : 0.5569079647455262\n",
      "Cost after the 1700(st) iteration : 0.5548697326223685\n",
      "Cost after the 1750(st) iteration : 0.5528316073363303\n",
      "Cost after the 1800(st) iteration : 0.5507931378146349\n",
      "Cost after the 1850(st) iteration : 0.5487421652594007\n",
      "Cost after the 1900(st) iteration : 0.5467041889844235\n",
      "Cost after the 1950(st) iteration : 0.544682529590943\n",
      "Cost after the 2000(st) iteration : 0.542655842626138\n",
      "Cost after the 2050(st) iteration : 0.5406296330978696\n",
      "Cost after the 2100(st) iteration : 0.5386106519877832\n",
      "Cost after the 2150(st) iteration : 0.5365884645890021\n",
      "Cost after the 2200(st) iteration : 0.5345846191549632\n",
      "Cost after the 2250(st) iteration : 0.5325787133369438\n",
      "Cost after the 2300(st) iteration : 0.5305348731783721\n",
      "Cost after the 2350(st) iteration : 0.52848357061497\n",
      "Cost after the 2400(st) iteration : 0.5264336032026504\n",
      "Cost after the 2450(st) iteration : 0.524414282115192\n",
      "Cost after the 2500(st) iteration : 0.5223931263609534\n",
      "Cost after the 2550(st) iteration : 0.520388804893272\n",
      "Cost after the 2600(st) iteration : 0.5183606513518833\n",
      "Cost after the 2650(st) iteration : 0.5163486112836948\n",
      "Cost after the 2700(st) iteration : 0.5143392264788248\n",
      "Cost after the 2750(st) iteration : 0.5123081750351487\n",
      "Cost after the 2800(st) iteration : 0.5102941381007204\n",
      "Cost after the 2850(st) iteration : 0.5082606775230263\n",
      "Cost after the 2900(st) iteration : 0.5062328603266639\n",
      "Cost after the 2950(st) iteration : 0.5041780874660923\n",
      "Cost after the 3000(st) iteration : 0.5021394420767544\n",
      "Cost after the 3050(st) iteration : 0.5001057992688742\n",
      "Cost after the 3100(st) iteration : 0.49808457171377046\n",
      "Cost after the 3150(st) iteration : 0.4960466671689011\n",
      "Cost after the 3200(st) iteration : 0.4939776634133557\n",
      "Cost after the 3250(st) iteration : 0.4919293114899664\n",
      "Cost after the 3300(st) iteration : 0.48987572693907805\n",
      "Cost after the 3350(st) iteration : 0.48782062529414394\n",
      "Cost after the 3400(st) iteration : 0.4857597101633528\n",
      "Cost after the 3450(st) iteration : 0.48373165506204874\n",
      "Cost after the 3500(st) iteration : 0.4816495323786635\n",
      "Cost after the 3550(st) iteration : 0.47957996297850713\n",
      "Cost after the 3600(st) iteration : 0.4774694136045771\n",
      "Cost after the 3650(st) iteration : 0.4753879998946064\n",
      "Cost after the 3700(st) iteration : 0.47328533403585604\n",
      "Cost after the 3750(st) iteration : 0.4711836206155106\n",
      "Cost after the 3800(st) iteration : 0.4690831444280417\n",
      "Cost after the 3850(st) iteration : 0.46700053246133727\n",
      "Cost after the 3900(st) iteration : 0.4648689130153694\n",
      "Cost after the 3950(st) iteration : 0.4627567546738745\n",
      "Cost after the 4000(st) iteration : 0.46060605055314224\n",
      "Cost after the 4050(st) iteration : 0.45849005410867383\n",
      "Cost after the 4100(st) iteration : 0.456332860615238\n",
      "Cost after the 4150(st) iteration : 0.4541576231776619\n",
      "Cost after the 4200(st) iteration : 0.4519513114886256\n",
      "Cost after the 4250(st) iteration : 0.4497382687908995\n",
      "Cost after the 4300(st) iteration : 0.44745707797090967\n",
      "Cost after the 4350(st) iteration : 0.44517248336436743\n",
      "Cost after the 4400(st) iteration : 0.4429109140950418\n",
      "Cost after the 4450(st) iteration : 0.4405979661242623\n",
      "Cost after the 4500(st) iteration : 0.43831270304368386\n",
      "Cost after the 4550(st) iteration : 0.43601492302914996\n",
      "Cost after the 4600(st) iteration : 0.433730202056243\n",
      "Cost after the 4650(st) iteration : 0.4314030818987295\n",
      "Cost after the 4700(st) iteration : 0.429095557982269\n",
      "Cost after the 4750(st) iteration : 0.42677761649905516\n",
      "Cost after the 4800(st) iteration : 0.4244571268475653\n",
      "Cost after the 4850(st) iteration : 0.42214684121092866\n",
      "Cost after the 4900(st) iteration : 0.41983507384466184\n",
      "Cost after the 4950(st) iteration : 0.41753124800314545\n",
      "Cost after the 5000(st) iteration : 0.41523450494435016\n",
      "Cost after the 5050(st) iteration : 0.4129145574015264\n",
      "Cost after the 5100(st) iteration : 0.4106282966348823\n",
      "Cost after the 5150(st) iteration : 0.4082993829674838\n",
      "Cost after the 5200(st) iteration : 0.4059902370686815\n",
      "Cost after the 5250(st) iteration : 0.4036787510745791\n",
      "Cost after the 5300(st) iteration : 0.4014077746100126\n",
      "Cost after the 5350(st) iteration : 0.39912218772827235\n",
      "Cost after the 5400(st) iteration : 0.3967971791671852\n",
      "Cost after the 5450(st) iteration : 0.39451156509140745\n",
      "Cost after the 5500(st) iteration : 0.39222021107267646\n",
      "Cost after the 5550(st) iteration : 0.38994539247013726\n",
      "Cost after the 5600(st) iteration : 0.3876563140144184\n",
      "Cost after the 5650(st) iteration : 0.38534801734262863\n",
      "Cost after the 5700(st) iteration : 0.3830689908700602\n",
      "Cost after the 5750(st) iteration : 0.380795814210307\n",
      "Cost after the 5800(st) iteration : 0.37851218944218623\n",
      "Cost after the 5850(st) iteration : 0.37620239449849713\n",
      "Cost after the 5900(st) iteration : 0.37393176056752975\n",
      "Cost after the 5950(st) iteration : 0.37166026738825786\n",
      "Cost after the 6000(st) iteration : 0.36939524563597614\n",
      "Accuracy on the train set : 84.21052631578948\n",
      "Initializing the parameters for a network with 2 hidden layers\n",
      "Number of units in hidden layers : [[20 10]]\n",
      "Accuracy on the test set : 66.0\n",
      "[[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      "  1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      "  1. 1.]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# try the model on with a one hidden layer\n",
    "Learning_rate  = 0.002\n",
    "Num_iterations = 6000\n",
    "L              = 3 # L-1 hidden layers\n",
    "Num_units_in_hidden_layers = np.array([[20],[10]])\n",
    "\n",
    "d1 = Modele_Deep_network(X_train, Y_train, X_test, Y_test, Learning_rate, Num_iterations, L, Num_units_in_hidden_layers)\n",
    "    \n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(d1[\"Iteration\"], d1[\"Cost\"])\n",
    "\n",
    "ax.set(xlabel='Epoc', ylabel='Cost',\n",
    "       title='Cats vs Non Cats ')\n",
    "ax.grid()   \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
