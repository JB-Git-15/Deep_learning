{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Own implementation of cat vs non cats challenge  (12/2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "import scipy\n",
    "from PIL import Image\n",
    "from scipy import ndimage\n",
    "#from lr_utils import load_dataset\n",
    "\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset():\n",
    "    train_dataset = h5py.File('datasets/train_catvnoncat.h5', \"r\")\n",
    "    train_set_x_orig = np.array(train_dataset[\"train_set_x\"][:]) # your train set features\n",
    "    train_set_y_orig = np.array(train_dataset[\"train_set_y\"][:]) # your train set labels\n",
    "\n",
    "    test_dataset = h5py.File('datasets/test_catvnoncat.h5', \"r\")\n",
    "    test_set_x_orig = np.array(test_dataset[\"test_set_x\"][:]) # your test set features\n",
    "    test_set_y_orig = np.array(test_dataset[\"test_set_y\"][:]) # your test set labels\n",
    "\n",
    "    classes = np.array(test_dataset[\"list_classes\"][:]) # the list of classes\n",
    "    \n",
    "    train_set_y_orig = train_set_y_orig.reshape((1, train_set_y_orig.shape[0]))\n",
    "    test_set_y_orig = test_set_y_orig.reshape((1, test_set_y_orig.shape[0]))\n",
    "    \n",
    "    return train_set_x_orig, train_set_y_orig, test_set_x_orig, test_set_y_orig, classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set_x_orig, train_set_y_orig, test_set_x_orig, test_set_y_orig, classes = load_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.66"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# majority class prediction\n",
    "\n",
    "# if predict all ones : 34 % of ones in the training set\n",
    "np.sum(train_set_y_orig)/train_set_y_orig.size\n",
    "\n",
    "# if predict all ones : 66 % of ones in the test set\n",
    "np.sum(test_set_y_orig)/test_set_y_orig.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "m =  train_set_x_orig.shape[0] # pictures training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape and normalize the data\n",
    "X_train = np.reshape(train_set_x_orig, (train_set_x_orig.shape[1]*train_set_x_orig.shape[2]*train_set_x_orig.shape[3],-1))\n",
    "Y_train = train_set_y_orig\n",
    "X_train = X_train/255\n",
    "m1      = X_train.shape[1]\n",
    "\n",
    "X_test  = np.reshape(test_set_x_orig,(test_set_x_orig.shape[1]*test_set_x_orig.shape[2]*test_set_x_orig.shape[3],-1))\n",
    "X_test  = X_test/255\n",
    "m2      = X_test.shape[1]\n",
    "\n",
    "Y_test  = test_set_y_orig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic regression gives an accuracy of 34.0 %\n"
     ]
    }
   ],
   "source": [
    "####### Essayer rÃ©gression logistique\n",
    "\n",
    "clf = LogisticRegressionCV(random_state=3, max_iter = 3000).fit(X_train.T, np.ravel(Y_train))\n",
    "Prediction = clf.predict(X_test.T)\n",
    "\n",
    "print(\"Logistic regression gives an accuracy of \" + str(100- np.mean(np.abs(Prediction - Y_test))*100) + \" %\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ReLu(x):\n",
    "    return np.maximum(0,x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ReLu_prime(z):\n",
    "    return (z>0)*1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Sigmoid(z):\n",
    "    return 1/(1+np.exp(-z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Sigmoid_prime(z):\n",
    "    return Sigmoid(z)*(1-Sigmoid(z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Init_parameters(X,y,L,Num_units_in_hidden_layers):\n",
    "    \n",
    "    m                          = X.shape[1]   # examples \n",
    "    Num_units_in_hidden_layers = np.reshape(Num_units_in_hidden_layers,(Num_units_in_hidden_layers.size,-1))\n",
    "    \n",
    "    if (Num_units_in_hidden_layers.size != (L-1)):\n",
    "        print('The number of units in the hidden layer are not consistent with the number of layers')\n",
    "    else:\n",
    "        print('Initializing the parameters for a network with ' + str(L-1) + ' hidden layers')\n",
    "        print('Number of units in hidden layers : ' + str(Num_units_in_hidden_layers.T))\n",
    "\n",
    "    \n",
    "    Num_u            = np.ones((L+1,1))    \n",
    "    Num_u[0]         = X.shape[0]\n",
    "    Num_u[-1]        = 1\n",
    "    Num_u[1:-1]      = Num_units_in_hidden_layers\n",
    "                \n",
    "    W_weights        = {}\n",
    "    B_biases         = {}\n",
    "\n",
    "    for u in range(L):\n",
    "        W_weights[\"W_\" + str(int(u+1))] =  np.random.randn(int(Num_u[u+1]),int(Num_u[u])) / np.sqrt(Num_u[u])\n",
    "        B_biases[\"B_\" + str(int(u+1))]  =  np.zeros((int(Num_u[u+1]),1)) \n",
    "        \n",
    "    A_activations    = {}  # activation functions    \n",
    "    for u in range(L+1):    \n",
    "        if u == 0:\n",
    "            A_activations[\"A_0\"] = X\n",
    "        else:    \n",
    "            A_activations[\"A_\" + str(int(u))]  = np.zeros((int(Num_u[int(u)]),m))\n",
    "    \n",
    "    Z_scores         = {} #scores                \n",
    "    for u in range(1,L+1):\n",
    "            Z_scores[\"Z_\" + str(int(u))]       = np.zeros((int(Num_u[int(u)]),m))\n",
    "          \n",
    "    G_non_lin            = {}\n",
    "    G_non_lin_derivative = {}\n",
    "    for u in range(L):    \n",
    "        if u != (L-1):\n",
    "            G_non_lin[\"g_\" + str(int(u+1))] = ReLu\n",
    "            G_non_lin_derivative[\"g'_\" + str(int(u+1))] = ReLu_prime\n",
    "        else:\n",
    "            G_non_lin[\"g_\" + str(int(u+1))] = Sigmoid\n",
    "            G_non_lin_derivative[\"g'_\" + str(int(u+1))] = Sigmoid_prime\n",
    "\n",
    "   \n",
    "    return W_weights,B_biases, Z_scores, A_activations, G_non_lin, G_non_lin_derivative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing the parameters for a network with 2 hidden layers\n",
      "Number of units in hidden layers : [[5 6]]\n"
     ]
    }
   ],
   "source": [
    "L = 3\n",
    "W_weights,B_biases,Z_scores,A_activations,G_non_lin,G_non_lin_derivative = Init_parameters(X_train,Y_train,L,np.array([[5],[6]]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Compute_cost(A_s,Y,L):\n",
    "    m      = Y.size\n",
    "    A_end  = A_s[\"A_\"+str(L)]\n",
    "    J      = np.sum(-(1-Y)*np.log(1-A_end)-Y*np.log(A_end))/m # compute \n",
    "    return J"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#A_activations[\"A_3\"] = Sigmoid(.9*Y_train +  np.random.rand(1,209)*.001)\n",
    "#Compute_cost(A_activations,Y_train,L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12288, 209)\n",
      "(5, 12288)\n"
     ]
    }
   ],
   "source": [
    "print(A_activations[\"A_0\"].shape)\n",
    "print(W_weights[\"W_1\"].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Forward_pass(L, W_weights,B_biases, Z_scores, A_activations,G_non_lin):\n",
    "\n",
    "    for u in range(L):\n",
    "        Z_scores[\"Z_\" + str(int(u+1))]      = np.dot(W_weights[\"W_\" + str(int(u+1))],A_activations[\"A_\" + str(int(u))]) + B_biases[\"B_\" + str(int(u+1))]\n",
    "        A_activations[\"A_\" + str(int(1+u))] = G_non_lin[\"g_\"+ str(int(u+1))](Z_scores[\"Z_\" + str(int(u+1))])\n",
    "    \n",
    "    return A_activations,Z_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Back_propagation(A_activations,W_weights,Z_scores,Y,L,G_non_lin_derivative):\n",
    "    \n",
    "    m                    = Y.size\n",
    "    A_end                = A_activations[\"A_\"+str(L)]\n",
    "    Delta_activations_dA = {}\n",
    "    Delta_scores_dZ      = {}\n",
    "    dW_s                 = {}\n",
    "    dB_s                 = {}\n",
    "    Delta_activations_dA[\"dA_\"+ str(int(L))]   = -np.divide(Y,A_end)  +  np.divide(1-Y,1-A_end)\n",
    "  \n",
    "       \n",
    "    for u in range(L,0,-1):    \n",
    "        Delta_scores_dZ[\"dZ_\"+ str(int(u))]            =  Delta_activations_dA[\"dA_\" + str(int(u))]*G_non_lin_derivative[\"g'_\" + str(int(u))](Z_scores[\"Z_\" + str(int(u))]) \n",
    "        dW_s[\"dW_\"+ str(int(u))]                       =  np.dot(Delta_scores_dZ[\"dZ_\"+ str(int(u))],A_activations[\"A_\"+str(u-1)].T)/m\n",
    "        dB_s[\"dB_\"+ str(int(u))]                       =  np.sum(Delta_scores_dZ[\"dZ_\"+ str(int(u))],axis = 1,keepdims = True)/m\n",
    "        Delta_activations_dA[\"dA_\" + str(int(u-1))]    =  np.dot(W_weights[\"W_\" + str(int(u))].T,Delta_scores_dZ[\"dZ_\"+ str(int(u))]) \n",
    " \n",
    "                         \n",
    "    return dW_s,dB_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Update_parameters(Weigth_matrices,dW_s,B_biases,dB_s,Learning_rate):\n",
    "    for u in range(1,len(Weigth_matrices)):      \n",
    "        Weigth_matrices[\"W_\"+str(u)] =  Weigth_matrices[\"W_\"+str(u)]  - Learning_rate*dW_s[\"dW_\"+ str(u)]\n",
    "        B_biases[\"B_\"+str(u)]        =  B_biases[\"B_\"+str(u)]  - Learning_rate*dB_s[\"dB_\"+ str(u)]\n",
    "  \n",
    "    return Weigth_matrices,B_biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Modele_Deep_network(X_train, Y_train, X_test, Y_test, Learning_rate, Num_iterations, L, Num_units_in_hidden_layers):\n",
    "    \n",
    "    W_weights,B_biases, Z_scores, A_activations, G_non_lin,G_non_lin_derivative = Init_parameters(X_train,Y_train,L,Num_units_in_hidden_layers)\n",
    "             \n",
    "    Cost_list      = [] \n",
    "    Iteration_list = [] \n",
    "    for num_iter in range(Num_iterations+1):\n",
    "            A_activations,Z_scores = Forward_pass(L, W_weights,B_biases, Z_scores, A_activations,G_non_lin)\n",
    "            dW_s,dB_s              = Back_propagation(A_activations,W_weights,Z_scores,Y_train,L,G_non_lin_derivative) \n",
    "            W_weights, B_biases    = Update_parameters(W_weights,dW_s,B_biases,dB_s,Learning_rate)\n",
    "        \n",
    "            if (num_iter%50 == 0):\n",
    "                Cost = Compute_cost(A_activations,Y_train,L)\n",
    "                print(\"Cost after the \"+ str(num_iter) +\"(st) iteration : \" + str(Cost)) \n",
    "                Cost_list.append(Cost) \n",
    "                Iteration_list.append(num_iter)\n",
    "    \n",
    "    #Accuracy on the train set\n",
    "    Preds_train = np.round(A_activations[\"A_\"+str(L)])\n",
    "    print(\"Accuracy on the train set : \" + str(100- np.mean(np.absolute(Preds_train - Y_train))*100))\n",
    "\n",
    "    #Accuracy on the test set\n",
    "    W_weights2,B_biases2, Z_scores2, A_activations2, G_non_lin,G_non_lin_derivative  = Init_parameters(X_test,Y_test,L,Num_units_in_hidden_layers)\n",
    "    A_activations2,x = Forward_pass(L, W_weights2,B_biases2, Z_scores2, A_activations2,G_non_lin)\n",
    "    Preds_test       = np.round(A_activations2[\"A_\"+str(L)])\n",
    "    print(\"Accuracy on the test set : \" + str(np.mean((Preds_test == Y_test))*100))\n",
    "       \n",
    "    d = {}\n",
    "    d['W'] = W_weights\n",
    "    d['B'] = B_biases\n",
    "    d['Acc train set'] = Preds_train\n",
    "    d['Acc test set']  = Preds_test\n",
    "    d['Cost'] = Cost_list\n",
    "    d['Iteration'] = Iteration_list\n",
    "        \n",
    "    print(Preds_train)    \n",
    "    print(Preds_test)    \n",
    "    \n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing the parameters for a network with 2 hidden layers\n",
      "Number of units in hidden layers : [[20 10]]\n",
      "Cost after the 0(st) iteration : 0.6512524117997981\n",
      "Cost after the 50(st) iteration : 0.5937923997236819\n",
      "Cost after the 100(st) iteration : 0.5702793553907555\n",
      "Cost after the 150(st) iteration : 0.5505711766482887\n",
      "Cost after the 200(st) iteration : 0.5345562156146731\n",
      "Cost after the 250(st) iteration : 0.5217041498171608\n",
      "Cost after the 300(st) iteration : 0.5120691110079051\n",
      "Cost after the 350(st) iteration : 0.5018534610276619\n",
      "Cost after the 400(st) iteration : 0.4925559040050609\n",
      "Cost after the 450(st) iteration : 0.48141886378262994\n",
      "Cost after the 500(st) iteration : 0.47671691923633425\n",
      "Cost after the 550(st) iteration : 0.4682896814840153\n",
      "Cost after the 600(st) iteration : 0.4599982864590124\n",
      "Cost after the 650(st) iteration : 0.4487747761976952\n",
      "Cost after the 700(st) iteration : 0.44352094140188636\n",
      "Cost after the 750(st) iteration : 0.43682544438448273\n",
      "Cost after the 800(st) iteration : 0.431898226345836\n",
      "Cost after the 850(st) iteration : 0.42418045846389296\n",
      "Cost after the 900(st) iteration : 0.4224132772788566\n",
      "Cost after the 950(st) iteration : 0.4094096603620416\n",
      "Cost after the 1000(st) iteration : 0.41433426585450867\n",
      "Cost after the 1050(st) iteration : 0.40249748189481566\n",
      "Cost after the 1100(st) iteration : 0.408184755392913\n",
      "Cost after the 1150(st) iteration : 0.39244510290371853\n",
      "Cost after the 1200(st) iteration : 0.3909030358230094\n",
      "Cost after the 1250(st) iteration : 0.39580571077697746\n",
      "Cost after the 1300(st) iteration : 0.37824780596260965\n",
      "Cost after the 1350(st) iteration : 0.39192911055651125\n",
      "Cost after the 1400(st) iteration : 0.3839098871200878\n",
      "Cost after the 1450(st) iteration : 0.3700792566346251\n",
      "Cost after the 1500(st) iteration : 0.3796359348100089\n",
      "Cost after the 1550(st) iteration : 0.3686474216120877\n",
      "Cost after the 1600(st) iteration : 0.36142221730948404\n",
      "Cost after the 1650(st) iteration : 0.3696519377116263\n",
      "Cost after the 1700(st) iteration : 0.35386713017261984\n",
      "Cost after the 1750(st) iteration : 0.3565783589071185\n",
      "Cost after the 1800(st) iteration : 0.35889825213687604\n",
      "Cost after the 1850(st) iteration : 0.348331909774046\n",
      "Cost after the 1900(st) iteration : 0.34638994918624144\n",
      "Cost after the 1950(st) iteration : 0.33475609145053464\n",
      "Cost after the 2000(st) iteration : 0.3480664725540617\n",
      "Cost after the 2050(st) iteration : 0.3299537831933543\n",
      "Cost after the 2100(st) iteration : 0.342725060182436\n",
      "Cost after the 2150(st) iteration : 0.3238511674386667\n",
      "Cost after the 2200(st) iteration : 0.3254842220346703\n",
      "Cost after the 2250(st) iteration : 0.31953852893011697\n",
      "Cost after the 2300(st) iteration : 0.33399290818450855\n",
      "Cost after the 2350(st) iteration : 0.3081504365173384\n",
      "Cost after the 2400(st) iteration : 0.30607844407463497\n",
      "Cost after the 2450(st) iteration : 0.3171331022277539\n",
      "Cost after the 2500(st) iteration : 0.3059766321336389\n",
      "Cost after the 2550(st) iteration : 0.3018931461200863\n",
      "Cost after the 2600(st) iteration : 0.299051375568704\n",
      "Cost after the 2650(st) iteration : 0.2924019180305783\n",
      "Cost after the 2700(st) iteration : 0.28832408084115396\n",
      "Cost after the 2750(st) iteration : 0.3088330881917644\n",
      "Cost after the 2800(st) iteration : 0.2797536611713278\n",
      "Cost after the 2850(st) iteration : 0.2963150962827941\n",
      "Cost after the 2900(st) iteration : 0.2737176891066112\n",
      "Cost after the 2950(st) iteration : 0.2893125672022529\n",
      "Cost after the 3000(st) iteration : 0.2697270012290396\n",
      "Cost after the 3050(st) iteration : 0.2815401098313351\n",
      "Cost after the 3100(st) iteration : 0.2581560266968667\n",
      "Cost after the 3150(st) iteration : 0.2640589978310762\n",
      "Cost after the 3200(st) iteration : 0.2719088543831998\n",
      "Cost after the 3250(st) iteration : 0.2535362483459199\n",
      "Cost after the 3300(st) iteration : 0.26740018460166554\n",
      "Cost after the 3350(st) iteration : 0.24346053175153504\n",
      "Cost after the 3400(st) iteration : 0.277957437300462\n",
      "Cost after the 3450(st) iteration : 0.2326667610091444\n",
      "Cost after the 3500(st) iteration : 0.23379688388720715\n",
      "Cost after the 3550(st) iteration : 0.2708361125826002\n",
      "Cost after the 3600(st) iteration : 0.21788478421402147\n",
      "Cost after the 3650(st) iteration : 0.23719887970469122\n",
      "Cost after the 3700(st) iteration : 0.25437755419284624\n",
      "Cost after the 3750(st) iteration : 0.20739284248437947\n",
      "Cost after the 3800(st) iteration : 0.2189099993035019\n",
      "Cost after the 3850(st) iteration : 0.2577205975240365\n",
      "Cost after the 3900(st) iteration : 0.19575488764318896\n",
      "Cost after the 3950(st) iteration : 0.19420986447853206\n",
      "Cost after the 4000(st) iteration : 0.254568311352888\n",
      "Cost after the 4050(st) iteration : 0.2238411793245404\n",
      "Cost after the 4100(st) iteration : 0.17471331852155228\n",
      "Cost after the 4150(st) iteration : 0.17844786558987225\n",
      "Cost after the 4200(st) iteration : 0.24138105625563486\n",
      "Cost after the 4250(st) iteration : 0.22545985046330028\n",
      "Cost after the 4300(st) iteration : 0.16058565765584704\n",
      "Cost after the 4350(st) iteration : 0.16030392170286376\n",
      "Cost after the 4400(st) iteration : 0.17903316604921446\n",
      "Cost after the 4450(st) iteration : 0.2971305564459614\n",
      "Cost after the 4500(st) iteration : 0.18024742861157844\n",
      "Cost after the 4550(st) iteration : 0.14450298903776124\n",
      "Cost after the 4600(st) iteration : 0.14562131935901548\n",
      "Cost after the 4650(st) iteration : 0.14961575663591345\n",
      "Cost after the 4700(st) iteration : 0.16028765844163706\n",
      "Cost after the 4750(st) iteration : 0.16136434710556116\n",
      "Cost after the 4800(st) iteration : 0.15462259988096103\n",
      "Cost after the 4850(st) iteration : 0.15313433015064887\n",
      "Cost after the 4900(st) iteration : 0.15084310482563193\n",
      "Cost after the 4950(st) iteration : 0.21823514652228018\n",
      "Cost after the 5000(st) iteration : 0.2741614983892338\n",
      "Cost after the 5050(st) iteration : 0.12303781476032771\n",
      "Cost after the 5100(st) iteration : 0.12149787633228307\n",
      "Cost after the 5150(st) iteration : 0.12010047025086398\n",
      "Cost after the 5200(st) iteration : 0.11871183141232804\n",
      "Cost after the 5250(st) iteration : 0.11836671927280709\n",
      "Cost after the 5300(st) iteration : 0.11590135311130198\n",
      "Cost after the 5350(st) iteration : 0.11386207763091566\n",
      "Cost after the 5400(st) iteration : 0.11278049140625043\n",
      "Cost after the 5450(st) iteration : 0.11238762902271934\n",
      "Cost after the 5500(st) iteration : 0.10904475647206784\n",
      "Cost after the 5550(st) iteration : 0.10862761201245645\n",
      "Cost after the 5600(st) iteration : 0.10668380269383418\n",
      "Cost after the 5650(st) iteration : 0.10492551389628749\n",
      "Cost after the 5700(st) iteration : 0.10336198398669195\n",
      "Cost after the 5750(st) iteration : 0.10209265218816672\n",
      "Cost after the 5800(st) iteration : 0.10048888576016145\n",
      "Cost after the 5850(st) iteration : 0.09857139072226855\n",
      "Cost after the 5900(st) iteration : 0.09683652874174893\n",
      "Cost after the 5950(st) iteration : 0.09630905738375352\n",
      "Cost after the 6000(st) iteration : 0.09331112719401874\n",
      "Cost after the 6050(st) iteration : 0.09244398778573393\n",
      "Cost after the 6100(st) iteration : 0.09088593116537115\n",
      "Cost after the 6150(st) iteration : 0.08953932098020015\n",
      "Cost after the 6200(st) iteration : 0.08803948266755746\n",
      "Cost after the 6250(st) iteration : 0.08630233806554585\n",
      "Cost after the 6300(st) iteration : 0.08598874044079612\n",
      "Cost after the 6350(st) iteration : 0.08444142246639091\n",
      "Cost after the 6400(st) iteration : 0.08261430949545595\n",
      "Cost after the 6450(st) iteration : 0.08174024223997219\n",
      "Cost after the 6500(st) iteration : 0.0806977483647126\n",
      "Cost after the 6550(st) iteration : 0.07949562343601611\n",
      "Cost after the 6600(st) iteration : 0.07824000045634318\n",
      "Cost after the 6650(st) iteration : 0.07742759235065991\n",
      "Cost after the 6700(st) iteration : 0.07603430338776793\n",
      "Cost after the 6750(st) iteration : 0.07502135474896246\n",
      "Cost after the 6800(st) iteration : 0.07348515586338712\n",
      "Cost after the 6850(st) iteration : 0.07283356377277948\n",
      "Cost after the 6900(st) iteration : 0.07218882772061677\n",
      "Cost after the 6950(st) iteration : 0.07058801004654805\n",
      "Cost after the 7000(st) iteration : 0.07006191276061938\n",
      "Cost after the 7050(st) iteration : 0.06952569977746294\n",
      "Cost after the 7100(st) iteration : 0.06831012314517688\n",
      "Cost after the 7150(st) iteration : 0.06708442397786035\n",
      "Cost after the 7200(st) iteration : 0.06645668450855997\n",
      "Cost after the 7250(st) iteration : 0.06562041414278098\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after the 7300(st) iteration : 0.06473875883373419\n",
      "Cost after the 7350(st) iteration : 0.06401306855334692\n",
      "Cost after the 7400(st) iteration : 0.06291166846326414\n",
      "Cost after the 7450(st) iteration : 0.062213353058875785\n",
      "Cost after the 7500(st) iteration : 0.06163422692981785\n",
      "Cost after the 7550(st) iteration : 0.06083722723941468\n",
      "Cost after the 7600(st) iteration : 0.05990268709181158\n",
      "Cost after the 7650(st) iteration : 0.05944859603048854\n",
      "Cost after the 7700(st) iteration : 0.05847748315417149\n",
      "Cost after the 7750(st) iteration : 0.057751606181173164\n",
      "Cost after the 7800(st) iteration : 0.05722106254883722\n",
      "Cost after the 7850(st) iteration : 0.05643632521305065\n",
      "Cost after the 7900(st) iteration : 0.05581749997922615\n",
      "Cost after the 7950(st) iteration : 0.05525505848949399\n",
      "Cost after the 8000(st) iteration : 0.054661499400532006\n",
      "Cost after the 8050(st) iteration : 0.05397709014052014\n",
      "Cost after the 8100(st) iteration : 0.05333422724657605\n",
      "Cost after the 8150(st) iteration : 0.05268848501680795\n",
      "Cost after the 8200(st) iteration : 0.05217147301393139\n",
      "Cost after the 8250(st) iteration : 0.05138429853794415\n",
      "Cost after the 8300(st) iteration : 0.0507977598746247\n",
      "Cost after the 8350(st) iteration : 0.050354729771305395\n",
      "Cost after the 8400(st) iteration : 0.049664957733499424\n",
      "Cost after the 8450(st) iteration : 0.0492245507175905\n",
      "Cost after the 8500(st) iteration : 0.048720231987199145\n",
      "Cost after the 8550(st) iteration : 0.04819375870722798\n",
      "Cost after the 8600(st) iteration : 0.047670852149870234\n",
      "Cost after the 8650(st) iteration : 0.0470637913255379\n",
      "Cost after the 8700(st) iteration : 0.04677131292311814\n",
      "Cost after the 8750(st) iteration : 0.046112196442618505\n",
      "Cost after the 8800(st) iteration : 0.045544605969642715\n",
      "Cost after the 8850(st) iteration : 0.04508598471967597\n",
      "Cost after the 8900(st) iteration : 0.044594698713409146\n",
      "Cost after the 8950(st) iteration : 0.04414879814212653\n",
      "Cost after the 9000(st) iteration : 0.04372701439953947\n",
      "Cost after the 9050(st) iteration : 0.04332592707191492\n",
      "Cost after the 9100(st) iteration : 0.04292180645435122\n",
      "Cost after the 9150(st) iteration : 0.04236333684907088\n",
      "Cost after the 9200(st) iteration : 0.04192339547133178\n",
      "Cost after the 9250(st) iteration : 0.041577663990195676\n",
      "Cost after the 9300(st) iteration : 0.041147751447375196\n",
      "Cost after the 9350(st) iteration : 0.040689583321289226\n",
      "Cost after the 9400(st) iteration : 0.040295215169531086\n",
      "Cost after the 9450(st) iteration : 0.03987719775512015\n",
      "Cost after the 9500(st) iteration : 0.03950372060866822\n",
      "Cost after the 9550(st) iteration : 0.039139990748336816\n",
      "Cost after the 9600(st) iteration : 0.03880414185488846\n",
      "Cost after the 9650(st) iteration : 0.03850953637490979\n",
      "Cost after the 9700(st) iteration : 0.03803605201763074\n",
      "Cost after the 9750(st) iteration : 0.03766051403681215\n",
      "Cost after the 9800(st) iteration : 0.03729637086583135\n",
      "Cost after the 9850(st) iteration : 0.0369650342352838\n",
      "Cost after the 9900(st) iteration : 0.03661056439643254\n",
      "Cost after the 9950(st) iteration : 0.03627445441584857\n",
      "Cost after the 10000(st) iteration : 0.03592854553160766\n",
      "Accuracy on the train set : 100.0\n",
      "Initializing the parameters for a network with 2 hidden layers\n",
      "Number of units in hidden layers : [[20 10]]\n",
      "Accuracy on the test set : 62.0\n",
      "[[0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 1. 1. 1. 1. 1.\n",
      "  1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      "  1. 1.]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# try the model on with a one hidden layer\n",
    "Learning_rate  = 0.0025\n",
    "Num_iterations = 10000\n",
    "L              = 3 # L-1 hidden layers\n",
    "Num_units_in_hidden_layers = np.array([[20],[10]])\n",
    "\n",
    "d1 = Modele_Deep_network(X_train, Y_train, X_test, Y_test, Learning_rate, Num_iterations, L, Num_units_in_hidden_layers)\n",
    "    \n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(d1[\"Iteration\"], d1[\"Cost\"])\n",
    "\n",
    "ax.set(xlabel='Epoc', ylabel='Cost',\n",
    "       title='Cats vs Non Cats ')\n",
    "ax.grid()   \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
